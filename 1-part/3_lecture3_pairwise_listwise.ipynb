{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RankNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$C_{ij}=C(o_{ij})=-\\bar{P_{ij}}log(P_{ij})-(1-\\bar{P_{ij}})log(1-P_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$o_{ij}=f(x_i)-f(x_j)$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$o_{ij}=f(x_i)-f(x_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$P_{ij}=\\frac{e^{o_{ij}}}{1+e^{o_{ij}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{out}_{i} = \\frac{1}{1 + e^{-\\text{input}_{i}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "        \n",
    "        self.out_activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        logits_1 = self.predict(input_1)\n",
    "        logits_2 = self.predict(input_2)\n",
    "        \n",
    "        logits_diff = logits_1 - logits_2\n",
    "        out = self.out_activation(logits_diff)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        logits = self.model(inp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model = RankNet(num_input_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0532, 0.4993, 0.7645, 0.0702, 0.3200, 0.3427, 0.3579, 0.7294, 0.3162,\n",
       "         0.7681],\n",
       "        [0.8687, 0.1679, 0.9260, 0.1604, 0.8834, 0.7331, 0.7024, 0.9545, 0.0521,\n",
       "         0.5836],\n",
       "        [0.8555, 0.6871, 0.0532, 0.2254, 0.8835, 0.4444, 0.8803, 0.2107, 0.2026,\n",
       "         0.0426],\n",
       "        [0.2593, 0.5056, 0.0537, 0.9563, 0.2461, 0.5078, 0.5954, 0.9523, 0.7879,\n",
       "         0.8331]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1, inp_2 = torch.rand(4, 10), torch.rand(4, 10)\n",
    "# batch_size x input_dim\n",
    "inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5300],\n",
       "        [0.5178],\n",
       "        [0.4611],\n",
       "        [0.5234]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ranknet_model(inp_1, inp_2)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranknet_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer = ranknet_model.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "loss = criterion(preds, torch.ones_like(preds))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9871e-03, -2.0317e-02, -1.3578e-02, -2.0541e-02, -8.0495e-04,\n",
       "         -5.8093e-03,  3.2482e-02,  1.9457e-02, -1.3675e-02, -7.3663e-04],\n",
       "        [ 3.3058e-03,  6.4443e-03,  6.8474e-04,  1.2189e-02,  3.1375e-03,\n",
       "          6.4726e-03,  7.5897e-03,  1.2139e-02,  1.0043e-02,  1.0619e-02],\n",
       "        [ 3.0231e-03,  9.3784e-03,  1.4491e-02,  1.7893e-02,  7.3732e-03,\n",
       "          9.1765e-03,  7.1943e-03,  2.6430e-02,  2.5375e-03,  1.7426e-02],\n",
       "        [ 3.6658e-03, -1.4934e-02, -9.9808e-03, -1.5099e-02, -5.9169e-04,\n",
       "         -4.2701e-03,  2.3876e-02,  1.4302e-02, -1.0052e-02, -5.4146e-04],\n",
       "        [ 2.2958e-03, -9.3529e-03, -6.2507e-03, -9.4558e-03, -3.7055e-04,\n",
       "         -2.6743e-03,  1.4953e-02,  8.9567e-03, -6.2953e-03, -3.3910e-04],\n",
       "        [-1.1595e-02, -1.0985e-02, -4.4955e-03, -6.5031e-03, -2.4134e-06,\n",
       "         -5.4944e-03, -1.5780e-04, -4.3601e-03, -1.0747e-02, -1.9958e-03],\n",
       "        [ 5.4647e-04,  5.0785e-03,  2.0652e-03,  7.2159e-03,  1.2585e-03,\n",
       "          3.1506e-03, -1.5551e-03,  1.8540e-03,  5.5115e-03,  3.9941e-03],\n",
       "        [ 2.3158e-03,  8.8154e-04,  3.8046e-03,  3.8847e-03,  1.1308e-02,\n",
       "          8.5844e-03, -1.0714e-03, -7.7917e-03,  7.2767e-03,  4.3022e-03],\n",
       "        [ 8.4936e-03,  1.1015e-03,  1.5819e-03,  2.5217e-03,  4.9968e-03,\n",
       "          4.0888e-04,  1.3625e-02,  1.2490e-02, -2.8866e-03,  7.2662e-03],\n",
       "        [ 1.4831e-03, -6.0422e-03, -4.0381e-03, -6.1086e-03, -2.3938e-04,\n",
       "         -1.7276e-03,  9.6598e-03,  5.7862e-03, -4.0669e-03, -2.1907e-04]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_linear_layer.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9871e-03, -2.0317e-02, -1.3578e-02, -2.0541e-02, -8.0495e-04,\n",
       "         -5.8093e-03,  3.2482e-02,  1.9457e-02, -1.3675e-02, -7.3663e-04],\n",
       "        [ 3.3058e-03,  6.4443e-03,  6.8474e-04,  1.2189e-02,  3.1375e-03,\n",
       "          6.4726e-03,  7.5897e-03,  1.2139e-02,  1.0043e-02,  1.0619e-02],\n",
       "        [ 3.0231e-03,  9.3784e-03,  1.4491e-02,  1.7893e-02,  7.3732e-03,\n",
       "          9.1765e-03,  7.1943e-03,  2.6430e-02,  2.5375e-03,  1.7426e-02],\n",
       "        [ 3.6658e-03, -1.4934e-02, -9.9808e-03, -1.5099e-02, -5.9169e-04,\n",
       "         -4.2701e-03,  2.3876e-02,  1.4302e-02, -1.0052e-02, -5.4146e-04],\n",
       "        [ 2.2958e-03, -9.3529e-03, -6.2507e-03, -9.4558e-03, -3.7055e-04,\n",
       "         -2.6743e-03,  1.4953e-02,  8.9567e-03, -6.2953e-03, -3.3910e-04],\n",
       "        [-1.1595e-02, -1.0985e-02, -4.4955e-03, -6.5031e-03, -2.4134e-06,\n",
       "         -5.4944e-03, -1.5780e-04, -4.3601e-03, -1.0747e-02, -1.9958e-03],\n",
       "        [ 5.4647e-04,  5.0785e-03,  2.0652e-03,  7.2159e-03,  1.2585e-03,\n",
       "          3.1506e-03, -1.5551e-03,  1.8540e-03,  5.5115e-03,  3.9941e-03],\n",
       "        [ 2.3158e-03,  8.8154e-04,  3.8046e-03,  3.8847e-03,  1.1308e-02,\n",
       "          8.5844e-03, -1.0714e-03, -7.7917e-03,  7.2767e-03,  4.3022e-03],\n",
       "        [ 8.4936e-03,  1.1015e-03,  1.5819e-03,  2.5217e-03,  4.9968e-03,\n",
       "          4.0888e-04,  1.3625e-02,  1.2490e-02, -2.8866e-03,  7.2662e-03],\n",
       "        [ 1.4831e-03, -6.0422e-03, -4.0381e-03, -6.1086e-03, -2.3938e-04,\n",
       "         -1.7276e-03,  9.6598e-03,  5.7862e-03, -4.0669e-03, -2.1907e-04]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranknet_model.model[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mic/Projects/github/python/ml-hard/1-part'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "# from utils import ndcg, num_swapped_pairs\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNet(torch.nn.Module):\n",
    "    def __init__(self, num_input_features, hidden_dim=10):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_features, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_1):\n",
    "        logits = self.model(input_1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$CE = -\\sum ^{N}_{j=1} (P_y^i(j) * log(P_z^i(j)))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listnet_ce_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i))\n",
    "\n",
    "def listnet_kl_loss(y_i, z_i):\n",
    "    \"\"\"\n",
    "    y_i: (n_i, 1) GT\n",
    "    z_i: (n_i, 1) preds\n",
    "    \"\"\"\n",
    "    P_y_i = torch.softmax(y_i, dim=0)\n",
    "    P_z_i = torch.softmax(z_i, dim=0)\n",
    "    return -torch.sum(P_y_i * torch.log(P_z_i/P_y_i))\n",
    "\n",
    "\n",
    "def make_dataset(N_train, N_valid, vector_dim):\n",
    "    fake_weights = torch.randn(vector_dim, 1)\n",
    "\n",
    "    X_train = torch.randn(N_train, vector_dim)\n",
    "    X_valid = torch.randn(N_valid, vector_dim)\n",
    "\n",
    "    ys_train_score = torch.mm(X_train, fake_weights)\n",
    "    ys_train_score += torch.randn_like(ys_train_score)\n",
    "\n",
    "    ys_valid_score = torch.mm(X_valid, fake_weights)\n",
    "    ys_valid_score += torch.randn_like(ys_valid_score)\n",
    "\n",
    "#     bins = [-1, 1]  # 3 relevances\n",
    "    bins = [-1, 0, 1, 2]  # 5 relevances\n",
    "    ys_train_rel = torch.Tensor(\n",
    "        np.digitize(ys_train_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "    ys_valid_rel = torch.Tensor(\n",
    "        np.digitize(ys_valid_score.clone().detach().numpy(), bins=bins)\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, ys_train_rel, ys_valid_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 1000\n",
    "N_valid = 500\n",
    "\n",
    "vector_dim = 100\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "X_train, X_valid, ys_train, ys_valid = make_dataset(N_train, N_valid, vector_dim)\n",
    "\n",
    "net = ListNet(num_input_features=vector_dim)\n",
    "opt = torch.optim.Adam(net.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 100]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, ys_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    idx = torch.randperm(N_train)\n",
    "\n",
    "    X_train = X_train[idx]\n",
    "    ys_train = ys_train[idx]\n",
    "\n",
    "    cur_batch = 0\n",
    "    for it in range(N_train // batch_size):\n",
    "        batch_X = X_train[cur_batch: cur_batch + batch_size]\n",
    "        batch_ys = ys_train[cur_batch: cur_batch + batch_size]\n",
    "        cur_batch += batch_size\n",
    "\n",
    "        opt.zero_grad()\n",
    "        if len(batch_X) > 0:\n",
    "            batch_pred = net(batch_X)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            batch_loss = listnet_kl_loss(batch_ys, batch_pred)\n",
    "#             batch_loss = listnet_ce_loss(batch_ys, batch_pred)\n",
    "            batch_loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_pred = net(X_valid)\n",
    "                valid_swapped_pairs = utils.num_swapped_pairs(ys_valid, valid_pred)\n",
    "                # import pdb; pdb.set_trace()\n",
    "                ndcg_score = utils.ndcg(ys_valid, valid_pred)\n",
    "            print(f\"epoch: {epoch + 1}.\\tNumber of swapped pairs: \" \n",
    "                  f\"{valid_swapped_pairs}/{N_valid * (N_valid - 1) // 2}\\t\"\n",
    "                  f\"nDCG: {ndcg_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
